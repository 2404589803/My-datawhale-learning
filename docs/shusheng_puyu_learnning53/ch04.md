# XTuner 大模型单卡低成本微调实战
## 视频笔记

### 一、Finetune两种方法原理简介

在LLM的下游应用中，**增量预训练**和**指令跟随**是两种常用到的微调方法。
#### 1.1 增量预训练原理介绍

增量预训练是LLM微调中最常用的一种方法。它通过在预训练模型的基础上添加额外的训练数据，来对模型进行微调。

使用场景：让基座模型学习到一些新知识，如某个垂类领域的常识。

训练数据：文章、书籍、代码等

#### 1.2 指令跟随原理介绍

指令跟随是另一种常用的微调方法。它通过在预训练模型的基础上添加额外的指令数据，来对模型进行微调。

使用场景：让模型学会对话模板，根据人类指令进行对话
训练数据：高质量的对话，问答数据。

模型训练的整个过程的详细流程如下：

![Alt text](%E4%B8%80%E4%B8%AA%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E7%9A%84%E6%B5%81%E7%A8%8B%E5%9B%BE.PNG)

通过海量数据训练，我们此时会得到一个基座模型。此时这个基座模型无法与人类进行正常问答，当我们直接询问基座模型时，它给出的数据是与是与输入的问题相近的回答，例如：给的问题是“什么是肝癌”，而模型给出的回答不是对肝癌的解释，而是输出“什么是肺癌”这种近似于所问问题的回答。

而当我们对模型进行**指令微调**时，我们就可以让模型学习到与人类对话相关的知识，从而让模型能够给出所问问题的解释。

### 二、Finetune两种方法实现过程简介

#### 2.1 增量预训练实现过程介绍



#### 2.2 指令跟随实现过程介绍

## 实践笔记

### 一、概述

#### 1.1 XTuner

一个大语言模型微调工具箱。由 MMRazor 和 MMDeploy 联合开发。

#### 1.2 支持的开源LLM (2023.11.01)

InternLM ✅
Llama，Llama2
ChatGLM2，ChatGLM3
Qwen
Baichuan，Baichuan2
Zephyr
.....................

#### 1.3 特色

🤓 傻瓜化： 以 配置文件 的形式封装了大部分微调场景，0基础的非专业人员也能一键开始微调。

🍃 轻量级： 对于 7B 参数量的LLM，微调所需的最小显存仅为 8GB ： 消费级显卡✅，colab✅

#### 1.4 微调原理
想象一下，你有一个超大的玩具，现在你想改造这个超大的玩具。但是，对整个玩具进行全面的改动会非常昂贵。

※ 因此，你找到了一种叫 LoRA 的方法：只对玩具中的某些零件进行改动，而不是对整个玩具进行全面改动。

※ 而 QLoRA 是 LoRA 的一种改进：如果你手里只有一把生锈的螺丝刀，也能改造你的玩具。

Full : 😳 → 🚲
LoRA : 😳 → 🛵
QLoRA : 😳 → 🏍

### 二、快速上手

#### 2.1 平台

Ubuntu + Anaconda + CUDA/CUDNN + 8GB nvidia显卡

#### 2.2 安装

