# 基于 InternLM 和 LangChain 搭建知识库

## 大模型的开发范式

LLM在近几年迎来井喷式爆发，涌现出很多优秀的开源大模型，如GPT-3.5、GPT-4、LLaMA，但是这些大模型都存在一定的局限性。

目前LLM主要存在以下问题：

1、知识时效性受限:如何才能让LLM能够获取最新的知识？
2、专业能力有限：如何打造垂直领域大模型？
3、定制化成本高：如何打造个人专属的LLM应用？

为了解决这些问题，我们就要对LLM进行二次开发。在目前基底大模型较固定的情况下，常见的LLM开发方式一般存在两种：**RAG**和**Finetune**。

RAG（Retrieval Augmented Generation），称为检索增强生成，是指在生成过程中加入检索模块，用于从知识库中检索相关内容。它的特点如下：

1、低成本
2、可实时更新
3、受基座影响大
4、单次回答知识有限

Finetune，称为微调，是指在预训练模型的基础上，对特定任务进行微调，以适应特定的任务需求。它的特点如下：

1、可个性化微调
2、知识覆盖面广
3、成本高昂
4、无法实时更新

首先，我们要指导RAG是如何运行的？

RAG的运行过程可以分为如下图所示的几个步骤：

![Alt text](%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%E8%BF%90%E8%A1%8C%E6%AD%A5%E9%AA%A4%E5%9B%BE.PNG)

用文字分步骤描述如下：

1、用户输入原始的自然语言prompt
2、使用开源的**词向量模型**（本教程使用的模型：Sentence Transformer）将输入的自然语言prompt转化为向量表示
3、将原始的自然语言prompt转化为向量表示后，在向量数据库中，搜寻匹配相似的向量
4、将匹配的向量和原始的自然语言prompt转化的向量进行拼接,然后作为一个新的prompt输入，最后再传递给LLM。

## 通用开发框架：LangChain

LangChain是一个基于Python的通用开发框架，用于构建基于LLM的应用程序。它提供了一组工具和库，使得开发人员能更加容易开发个性化LLM应用。



